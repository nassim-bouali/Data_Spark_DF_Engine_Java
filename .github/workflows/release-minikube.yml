name: Deploy to Minikube

on:
  push:
    branches:
      - master  # Project's main branch name

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Minikube
        run: |
          # Install Minikube
          curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
          chmod +x minikube
          sudo install minikube /usr/local/bin/
          
          # Start Minikube
          minikube start
        env:
          KUBECONFIG: ${{ runner.workspace }}/kubeconfig.yaml

      - name: Deploy to Minikube
        run: |
          kubectl apply -f ./deploy/batch-df-processing-engine-deployment.yaml
          kubectl wait --timeout=5m --for=condition=available deployment/batch-df-processing-engine-deployment
          POD_NAME=$(kubectl get pods --selector=app=batch-df-processing-engine -o jsonpath="{.items[0].metadata.name}")
          kubectl cp ./Data_Spark_DF_Application/src/test/resources/data $POD_NAME:/data
        env:
          KUBECONFIG: ${{ runner.workspace }}/kubeconfig.yaml

      - name: Verify Deployment
        run: |
          kubectl wait --timeout=5m --for=condition=available deployment/batch-df-processing-engine-deployment
          POD_NAME=$(kubectl get pods --selector=app=batch-df-processing-engine -o jsonpath="{.items[0].metadata.name}")
          kubectl logs -f $POD_NAME
        env:
          KUBECONFIG: ${{ runner.workspace }}/kubeconfig.yaml

      - name: Stop Minikube
        run: minikube stop

      # Add additional steps for testing, notifications, and cleanup as needed
